{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.강화학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 강화학습의 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "강화학습(Reinforcement Learning)을 이해하려면 강화학습과 행동심리학, 머신러닝의 연관성에 대해 알아야 합니다.\n",
    "Skinner라는 행동심리학자는 시행착오를 통해 학습하는 방법을 강화라는 개념으로 제시하였습니다. 동물들이 이것 저것 여러 행동을 시도해보면서 그 결과를 통해 행위를 학습하는 것을 말합니다.\n",
    "강화라는 개념에서 핵심적인 역할을 하는 것이 바로 보상입니다. 강화학습을 하는 동물의 경우 행동과 좋은 보상 사이의 상관관계를 학습하여 보상을 받는 빈도를 증가시키는 방향으로 행동합니다. = 강아지한테 간식으로 행동을 교정하는것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝과 강화학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여태까지 여러분들이 머신러닝을 공부하며 배운 개념은 크게 지도학습 그리고 비지도학습의 개념입니다. 지도학습의 경우 정답을 알고 있는 데이터를 이용해 학습을 시킵니다. 정답과 예측값의 차이를 이용해 학습합니다. 비지도학습은 정답이 있는 것은 아니지만 여러 데이터의 비슷한 것끼리 묶어주는 클러스터링을 이용한 학습이 비지도학습입니다. \n",
    "\n",
    "이 스터디에서 공부할 강화학습은 이 두 개념에서 벗어나 정답이 주어진 것도 아니고 데이터에 따라 학습하는 것도 아닙니다. 강화학습은 컴퓨터가 선택한 행동에 따른 보상을 기준으로 학습을 시킵니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 에이전트\n",
    "\n",
    "### 강화학습을 통해 학습하는 컴퓨터\n",
    "에이전트는 환경에 대한 사전지식이 없는 상태에서 학습을 시작합니다. 환경은 에이전트가 선택한 행동에 따라 보상을 주고 다음 상태를 알려줍니다. 이를 통해 에이전트는 어떤 행동이 최적의 행동인지 간접적으로 알게 됩니다.\n",
    "\n",
    "### 최적의 행동양식, 또는 정책\n",
    "강화학습의 목적은 에이전트가 환경을 탐색하면서 얻는 보상들의 합을 최대화하는 것입니다. 보상은 양수로 설정할 수도 있고 경우에 따라 음수로 설정할 수도 있습니다.\n",
    "상과 벌을 적절히 융합할 수 있으면 효과적인 학습이 가능합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 강화학습 문제\n",
    "강화학습은 결정을 순차적으로 내려야 하는 문제에 적용됩니다.\n",
    "## 순차적 행동 결정 문제\n",
    "에이전트가 학습하고 발전하려면 문제를 수학적으로 표현해야 합니다. EX) 학생들의 수학능력을 시험을 통해 수치적으로 표현\n",
    "\n",
    "순차적으로 행동을 결정하는 문제를 정의할 때 사용하는 방법이 MDP(Markov Decision Process)입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 순차적 행동 결정 문제의 구성 요소\n",
    "\n",
    "### 1) 상태\n",
    "에이전트의 현재 상태에 대한 정적인, 동적인 요소들 \n",
    "EX) 에이전트가 탁구를 친다고 가정할 때 \n",
    "정적인 요소 : 에이전트의 위치, 탁구공의 위치\n",
    "동적인 요소 : 속도, 가속도 \n",
    "### 2) 행동\n",
    "에이전트가 어떠한 상태에서 취할 수 있는 행동\n",
    "EX) 상화좌우로 움직이는 행동\n",
    "학습이 되지 않은 에이전트는 어떤 행동이 좋은 행동인지 모르기 때문에 무작위로 행동을 취합니다.\n",
    "### 3) 보상\n",
    "에이전트의 행동에 따라 지급되는 보상\n",
    "에이전트가 학습할 수 있는 유일한 정보\n",
    "### 4) 정책\n",
    "순차적 행동 결정 문제를 풀었다고 한다면 가장 좋은 정책을 에이전트가 얻었다는 의미입니다.\n",
    "에이전트가 학습을 통해 목표로 하는 것이 최적 정책입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 방대한 상태를 가진 문제에서의 강화학습\n",
    "\n",
    "바둑에서 가능한 경우의 수는 10^360개입니다. 경우의 수가 매우 많지만 유한개입니다. 그동안 성능의 문제로 바둑의 최적 정책을 해결하지 못했지만, 컴퓨터 성능의 향상으로 알파고가 탄생했습니다.\n",
    "하지만 로봇의 학습의 경우 로봇이 관찰하는 정보와 행동 보상이 연속적이기 때문에 가능한 경우의 수가 무한대에 가깝습니다. 로봇이 취할 수 있는 행동의 개수도 많아서 모델이 상당히 복잡해집니다. 강화학습과 인공신경망의 결합으로 로봇이 레고를 쌓는 정도의 학습이 가능해지게 되었습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 강화학습의 예시 : breakout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "env = gym.envs.make(\"Breakout-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Breakout은 흔히 벽돌깨기 게임으로 알려져 있습니다. 이 게임에서 에이전트는 정지, 발사, 왼쪽, 오른쪽 이 네 가지 행동을 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space size: 4\n",
      "['NOOP', 'FIRE', 'RIGHT', 'LEFT']\n",
      "Observation space shape: (210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Action space size: {}\".format(env.action_space.n)) #행동의 개수를 표시합니다.\n",
    "print(env.get_action_meanings()) #행동의 의미에 대해서 표시합니다.\n",
    "# env.unwrapped.get_action_meanings() for gym 0.8.0 or later\n",
    "\n",
    "observation = env.reset() #환경을 초기화합니다.\n",
    "print(\"Observation space shape: {}\".format(observation.shape)) #환경이 표시되는 공간의 크기를 표시합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10da7a1d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(env.render(mode='rgb_array')) #초기화된 환경을 표시합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-에이전트는 다음과 같은 방식으로 행동을 취합니다. 위의 초기화된 그림과 아래의 행동을 선택한 그림의 차이를 보면 어떤 방식으로 행동을 하는 지 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "[env.step(3) for x in range(3)] # 3번 행동을 3번 수행합니다.\n",
    "plt.figure()\n",
    "plt.imshow(env.render(mode='rgb_array')) #행동을 수행한 결과를 표시합니다. 오른쪽으로 3번 이동한 것을 볼 수 있습니다.\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출처 : https://github.com/dennybritz/reinforcement-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음 학습과 그 결과에 대한 코드와 결과는 별도로 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
